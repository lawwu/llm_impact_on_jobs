{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running llama2-13b locally on a Macbook Pro M1 32GB\n",
    "\n",
    "https://python.langchain.com/docs/integrations/llms/llamacpp#installation-with-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser, StructuredOutputParser, ResponseSchema\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import(\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "# Verbose is required to pass to the callback manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/lawrence.wu/Documents/github/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: mem required  = 7349.72 MB (+ 1600.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 1600.00 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: using MPS\n",
      "ggml_metal_init: loading '/Users/lawrence.wu/Documents/github/research-llms/venv/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x111596f20\n",
      "ggml_metal_init: loaded kernel_add_row                        0x100c3c8a0\n",
      "ggml_metal_init: loaded kernel_mul                            0x100cbe7f0\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x16e48bdd0\n",
      "ggml_metal_init: loaded kernel_scale                          0x16e48b4d0\n",
      "ggml_metal_init: loaded kernel_silu                           0x16e48c6d0\n",
      "ggml_metal_init: loaded kernel_relu                           0x100cbeff0\n",
      "ggml_metal_init: loaded kernel_gelu                           0x100cbf8f0\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x100cbfec0\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x111880690\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x1118808f0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x111880b50\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x111880db0\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x111881010\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x111881270\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x1118814d0\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x111881730\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x111881990\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x111881bf0\n",
      "ggml_metal_init: loaded kernel_norm                           0x111881e50\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x1118820b0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x111882310\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x111882570\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x1118827d0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x111882a30\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x111882c90\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x111882ef0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x111883150\n",
      "ggml_metal_init: loaded kernel_rope                           0x1118833b0\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x111883610\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x111883870\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x111883ad0\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x111883d30\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 21845.34 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "llama_new_context_with_model: max tensor size =    87.89 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  6984.06 MB, (15938.88 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =    12.00 MB, (15950.88 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1602.00 MB, (17552.88 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'scr0            ' buffer, size =   162.00 MB, (17714.88 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'scr1            ' buffer, size =   192.00 MB, (17906.88 / 21845.34)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
      "ggml_metal_free: deallocating\n"
     ]
    }
   ],
   "source": [
    "# Make sure the model path is correct for your system!\n",
    "MODEL_LLAMA2_13B = \"llama-2-13b-chat.ggmlv3.q4_0.bin\"\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "\n",
    "llm = LlamaCpp(\n",
    "            model_path=f\"/Users/lawrence.wu/Documents/github/llama.cpp/{MODEL_LLAMA2_13B}\",\n",
    "            temperature=0.7,\n",
    "            top_p=1,\n",
    "            max_tokens=2048,\n",
    "            n_ctx=2048,\n",
    "            n=-1,\n",
    "            repeat_penalty=1.1,\n",
    "            n_threads=8,\n",
    "            callback_manager=callback_manager,\n",
    "            n_gpu_layers=n_gpu_layers,\n",
    "            n_batch=2048,  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "            f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "            verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\n",
    "# Question: A rap battle between Stephen Colbert and John Oliver\n",
    "# \"\"\"\n",
    "# llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It's a question that has puzzled philosophers and theologians for centuries, and one that has been explored in various forms of media. Here are some of the most thought-provoking films, books, and TV shows that delve into this existential question:\n",
      "1. \"The Matrix\" (1999) - This iconic sci-fi film posits a world where humans are unknowingly trapped in a simulated reality created by intelligent machines. The main character, Neo, is awakened to this truth and must choose between embracing his newfound freedom or returning to the comfort of ignorance.\n",
      "2. \"The Tree of Life\" (2011) - This Oscar-nominated film follows a family over several decades, exploring their joys and struggles as they navigate life's ups and downs. The film is a meditation on the meaning of existence and the interconnectedness of all things.\n",
      "3. \"The Shawshank Redemption\" (1994) - This highly acclaimed drama tells the story of two prisoners who form an unlikely friendship and find hope in a bleak and unforgiving environment. The film is a powerful exploration of redemption, sacrifice, and the human spirit.\n",
      "4. \"The Hitchhiker's Guide to the Galaxy\" (2005) - This comedic sci-fi adventure follows an unwitting human and his alien friend as they travel through space, encountering strange creatures and absurd situations along the way. The film is a lighthearted exploration of the meaning of life and the importance of friendship.\n",
      "5. \"The Book of Life\" (2014) - This animated film tells the story of two young lovers who find themselves in a magical world where death is the ruler, and life is but a dream. The film is a beautiful exploration of the meaning of life and the power of love.\n",
      "6. \"The Leftovers\" (2014-2017) - This critically acclaimed TV series follows a group of people who are left behind after a global event that causes 2% of the world's population to vanish without explanation. The show is a thought-provoking exploration of grief, loss, and the human condition.\n",
      "7. \"The Handmaid's Tale\" (2017-) - Based on Margaret Atwood's novel of the same name, this Emmy-winning TV series is set in a dystopian future where women have lost all their rights and are forced into reproductive servitude. The show is a powerful exploration of oppression, resistance, and the human spirit.\n",
      "8. \"The Alchemist\" (2019) - This Netflix original film is based on Paulo Coelho's bestselling novel and follows a young shepherd on a journey to fulfill his dreams and find his Personal Legend. The film is a beautiful exploration of the power of belief, perseverance, and the meaning of life.\n",
      "9. \"The Lovely Bones\" (2009) - This haunting drama tells the story of a young girl who is murdered and observes her family from the afterlife as they cope with their grief and move on with their lives. The film is a powerful exploration of loss, love, and the meaning of life.\n",
      "10. \"The Hitchhiker's Guide to the Galaxy\" (2005) - This comedic sci-fi adventure follows an unwitting human and his alien friend as they travel through space, encountering strange creatures and absurd situations along the way. The film is a lighthearted exploration of the meaning of life and the importance of friendship.\n",
      "These films, books, and TV shows offer a variety of perspectives on the meaning of life, from philosophical and spiritual to comedic and lighthearted. They invite us to reflect on our own beliefs and values, and to cherish the preciousness of life and the connections we make with others."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.70 ms\n",
      "llama_print_timings:      sample time =   837.72 ms /   893 runs   (    0.94 ms per token,  1065.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3616.65 ms /     9 tokens (  401.85 ms per token,     2.49 tokens per second)\n",
      "llama_print_timings:        eval time = 59172.35 ms /   892 runs   (   66.34 ms per token,    15.07 tokens per second)\n",
      "llama_print_timings:       total time = 66526.86 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' It\\'s a question that has puzzled philosophers and theologians for centuries, and one that has been explored in various forms of media. Here are some of the most thought-provoking films, books, and TV shows that delve into this existential question:\\n1. \"The Matrix\" (1999) - This iconic sci-fi film posits a world where humans are unknowingly trapped in a simulated reality created by intelligent machines. The main character, Neo, is awakened to this truth and must choose between embracing his newfound freedom or returning to the comfort of ignorance.\\n2. \"The Tree of Life\" (2011) - This Oscar-nominated film follows a family over several decades, exploring their joys and struggles as they navigate life\\'s ups and downs. The film is a meditation on the meaning of existence and the interconnectedness of all things.\\n3. \"The Shawshank Redemption\" (1994) - This highly acclaimed drama tells the story of two prisoners who form an unlikely friendship and find hope in a bleak and unforgiving environment. The film is a powerful exploration of redemption, sacrifice, and the human spirit.\\n4. \"The Hitchhiker\\'s Guide to the Galaxy\" (2005) - This comedic sci-fi adventure follows an unwitting human and his alien friend as they travel through space, encountering strange creatures and absurd situations along the way. The film is a lighthearted exploration of the meaning of life and the importance of friendship.\\n5. \"The Book of Life\" (2014) - This animated film tells the story of two young lovers who find themselves in a magical world where death is the ruler, and life is but a dream. The film is a beautiful exploration of the meaning of life and the power of love.\\n6. \"The Leftovers\" (2014-2017) - This critically acclaimed TV series follows a group of people who are left behind after a global event that causes 2% of the world\\'s population to vanish without explanation. The show is a thought-provoking exploration of grief, loss, and the human condition.\\n7. \"The Handmaid\\'s Tale\" (2017-) - Based on Margaret Atwood\\'s novel of the same name, this Emmy-winning TV series is set in a dystopian future where women have lost all their rights and are forced into reproductive servitude. The show is a powerful exploration of oppression, resistance, and the human spirit.\\n8. \"The Alchemist\" (2019) - This Netflix original film is based on Paulo Coelho\\'s bestselling novel and follows a young shepherd on a journey to fulfill his dreams and find his Personal Legend. The film is a beautiful exploration of the power of belief, perseverance, and the meaning of life.\\n9. \"The Lovely Bones\" (2009) - This haunting drama tells the story of a young girl who is murdered and observes her family from the afterlife as they cope with their grief and move on with their lives. The film is a powerful exploration of loss, love, and the meaning of life.\\n10. \"The Hitchhiker\\'s Guide to the Galaxy\" (2005) - This comedic sci-fi adventure follows an unwitting human and his alien friend as they travel through space, encountering strange creatures and absurd situations along the way. The film is a lighthearted exploration of the meaning of life and the importance of friendship.\\nThese films, books, and TV shows offer a variety of perspectives on the meaning of life, from philosophical and spiritual to comedic and lighthearted. They invite us to reflect on our own beliefs and values, and to cherish the preciousness of life and the connections we make with others.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"What's the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For centuries, philosophers and theologians have been grappling with this question, and there is no one definitive answer. However, here are some possible perspectives on the meaning of life:\n",
      "\n",
      "1. Religious perspective: Many religious traditions teach that the purpose of life is to serve a higher power or to fulfill a divine plan. For example, some believe that the purpose of life is to love and worship God, while others believe that it is to follow the teachings of a particular religion or spiritual path.\n",
      "2. Personal fulfillment: Some people believe that the meaning of life is to find personal fulfillment and happiness. According to this view, individuals should pursue their passions and interests, cultivate meaningful relationships, and strive to live a life that is rich in experience and personal growth.\n",
      "3. Social and cultural perspective: Others believe that the meaning of life is tied to one's social and cultural context. For example, some people find meaning in their work, their family, or their community, while others find meaning in their involvement in social and political causes.\n",
      "4. Existentialist perspective: Existentialists like Jean-Paul Sartre and Martin Heidegger argue that the meaning of life is not predetermined or inherent, but rather something that individuals must create for themselves through their choices and actions. According to this view, life has no inherent meaning, but we can give it meaning by the way we live it.\n",
      "5. Biological perspective: From a biological perspective, the meaning of life might be seen as the perpetuation of the species or the survival of the fittest. In this view, the meaning of life is to reproduce and ensure the continuation of one's genetic lineage.\n",
      "6. Psychological perspective: Some psychologists argue that the meaning of life is found in the fulfillment of basic human needs such as the need for connection, purpose, and self-actualization. According to this view, individuals should strive to cultivate a sense of purpose and meaning in their lives by pursuing activities and relationships that fulfill these needs.\n",
      "7. Humanistic perspective: Finally, some people believe that the meaning of life is found in the human experience itself, rather than in any particular outcome or goal. According to this view, the meaning of life is to be found in the beauty, love, and wonder of human existence, rather than in any specific purpose or function.\n",
      "In conclusion, there is no one definitive answer to the question of what is the meaning of life, but rather a multitude of perspectives and interpretations. Ultimately, the meaning of life may be something that each individual must determine for themselves based on their own unique experiences, values, and beliefs."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.70 ms\n",
      "llama_print_timings:      sample time =   486.41 ms /   588 runs   (    0.83 ms per token,  1208.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 37882.36 ms /   588 runs   (   64.43 ms per token,    15.52 tokens per second)\n",
      "llama_print_timings:       total time = 40652.60 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nFor centuries, philosophers and theologians have been grappling with this question, and there is no one definitive answer. However, here are some possible perspectives on the meaning of life:\\n\\n1. Religious perspective: Many religious traditions teach that the purpose of life is to serve a higher power or to fulfill a divine plan. For example, some believe that the purpose of life is to love and worship God, while others believe that it is to follow the teachings of a particular religion or spiritual path.\\n2. Personal fulfillment: Some people believe that the meaning of life is to find personal fulfillment and happiness. According to this view, individuals should pursue their passions and interests, cultivate meaningful relationships, and strive to live a life that is rich in experience and personal growth.\\n3. Social and cultural perspective: Others believe that the meaning of life is tied to one's social and cultural context. For example, some people find meaning in their work, their family, or their community, while others find meaning in their involvement in social and political causes.\\n4. Existentialist perspective: Existentialists like Jean-Paul Sartre and Martin Heidegger argue that the meaning of life is not predetermined or inherent, but rather something that individuals must create for themselves through their choices and actions. According to this view, life has no inherent meaning, but we can give it meaning by the way we live it.\\n5. Biological perspective: From a biological perspective, the meaning of life might be seen as the perpetuation of the species or the survival of the fittest. In this view, the meaning of life is to reproduce and ensure the continuation of one's genetic lineage.\\n6. Psychological perspective: Some psychologists argue that the meaning of life is found in the fulfillment of basic human needs such as the need for connection, purpose, and self-actualization. According to this view, individuals should strive to cultivate a sense of purpose and meaning in their lives by pursuing activities and relationships that fulfill these needs.\\n7. Humanistic perspective: Finally, some people believe that the meaning of life is found in the human experience itself, rather than in any particular outcome or goal. According to this view, the meaning of life is to be found in the beauty, love, and wonder of human existence, rather than in any specific purpose or function.\\nIn conclusion, there is no one definitive answer to the question of what is the meaning of life, but rather a multitude of perspectives and interpretations. Ultimately, the meaning of life may be something that each individual must determine for themselves based on their own unique experiences, values, and beliefs.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"What's the meaning of life?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/lawrence.wu/Documents/github/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: mem required  = 7349.72 MB (+ 1600.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 1600.00 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: using MPS\n",
      "ggml_metal_init: loading '/Users/lawrence.wu/Documents/github/research-llms/venv/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x1129e00e0\n",
      "ggml_metal_init: loaded kernel_add_row                        0x112cd5c60\n",
      "ggml_metal_init: loaded kernel_mul                            0x112cd5ec0\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x112847170\n",
      "ggml_metal_init: loaded kernel_scale                          0x1126940e0\n",
      "ggml_metal_init: loaded kernel_silu                           0x1129dfde0\n",
      "ggml_metal_init: loaded kernel_relu                           0x1129e0560\n",
      "ggml_metal_init: loaded kernel_gelu                           0x112cd6120\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x112cd6380\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x112cd65e0\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x112cd6840\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x112cd6aa0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x112cd6d00\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x112cd6f60\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x112cd71c0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x112cd7420\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x112cd7680\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x112cd78e0\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x112cd7b40\n",
      "ggml_metal_init: loaded kernel_norm                           0x1126949e0\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x1126952e0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x112695be0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x1126961b0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x112696410\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x112696670\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x112693910\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x1126968e0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x112696b40\n",
      "ggml_metal_init: loaded kernel_rope                           0x112696da0\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x112697000\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x1129e07c0\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x1129e0a20\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x1129e0c80\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 21845.34 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "llama_new_context_with_model: max tensor size =    87.89 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  6984.06 MB, (15938.88 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =    12.00 MB, (15950.88 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1602.00 MB, (17552.88 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'scr0            ' buffer, size =   162.00 MB, (17714.88 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'scr1            ' buffer, size =   192.00 MB, (17906.88 / 21845.34)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
      "ggml_metal_free: deallocating\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "            model_path=f\"/Users/lawrence.wu/Documents/github/llama.cpp/{MODEL_LLAMA2_13B}\",\n",
    "            temperature=1,\n",
    "            top_p=1,\n",
    "            max_tokens=2048,\n",
    "            n_ctx=2048,\n",
    "            n=-1,\n",
    "            repeat_penalty=1.1,\n",
    "            n_threads=8,\n",
    "            callback_manager=callback_manager,\n",
    "            n_gpu_layers=n_gpu_layers,\n",
    "            n_batch=2048,  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "            f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "            verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a question that has puzzled philosophers and theologians for centuries, and there is no one definitive answer. However, here are some possible perspectives on this question:\n",
      "\n",
      "1. Biological perspective: From a biological perspective, the meaning of life is to survive and reproduce, as these are the fundamental drives that have shaped the evolution of life on Earth. However, this perspective does not provide much insight into the human experience or the nature of existence.\n",
      "2. Psychological perspective: From a psychological perspective, the meaning of life is to find fulfillment and happiness. This can be achieved through personal growth, relationships, and experiences that bring joy and satisfaction.\n",
      "3. Social perspective: From a social perspective, the meaning of life is to contribute to the greater good of society. This can be done through work, volunteering, or other forms of service that benefit others.\n",
      "4. Philosophical perspective: From a philosophical perspective, the meaning of life is a question that has been debated by thinkers throughout history. Some have argued that life has no inherent meaning, and that we must create our own purpose and meaning. Others have argued that life has a predetermined meaning or purpose, and that we must discover this through reflection and self-awareness.\n",
      "5. Religious perspective: From a religious perspective, the meaning of life is often seen as derived from a divine source. Many religions teach that the purpose of life is to serve and worship God, or to follow the teachings of a particular faith.\n",
      "6. Existentialist perspective: From an existentialist perspective, the meaning of life is not predetermined or inherent, but rather something that we must create for ourselves. This perspective emphasizes individual freedom and choice, and the idea that we must take responsibility for creating our own meaning in life.\n",
      "7. Humanistic perspective: From a humanistic perspective, the meaning of life is centered on human experience and fulfillment. This perspective emphasizes the importance of personal growth, relationships, and self-actualization.\n",
      "8. Cosmological perspective: From a cosmological perspective, the meaning of life is tied to the nature of the universe and our place in it. Some have argued that life is a rare and precious occurrence in an otherwise vast and empty universe, and that we must make the most of our time here.\n",
      "9. Evolutionary perspective: From an evolutionary perspective, the meaning of life is to survive and evolve as a species. This perspective emphasizes the importance of adaptation, innovation, and progress in the ongoing story of life on Earth.\n",
      "10. Mystical perspective: From a mystical perspective, the meaning of life is to connect with a higher power or ultimate reality. This perspective emphasizes the idea that our lives are part of a larger cosmic whole, and that we must cultivate a deep sense of inner peace and connection to find true meaning.\n",
      "In conclusion, the meaning of life is a complex and multifaceted question that has been debated by philosophers, theologians, and scientists for centuries. There is no one definitive answer, but rather a variety of perspectives that can help us understand this profound question. Ultimately, the meaning of life may be something that we must each discover for ourselves based on our own experiences, beliefs, and values."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2115.84 ms\n",
      "llama_print_timings:      sample time =   928.42 ms /   714 runs   (    1.30 ms per token,   769.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 48435.80 ms /   714 runs   (   67.84 ms per token,    14.74 tokens per second)\n",
      "llama_print_timings:       total time = 52765.75 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis is a question that has puzzled philosophers and theologians for centuries, and there is no one definitive answer. However, here are some possible perspectives on this question:\\n\\n1. Biological perspective: From a biological perspective, the meaning of life is to survive and reproduce, as these are the fundamental drives that have shaped the evolution of life on Earth. However, this perspective does not provide much insight into the human experience or the nature of existence.\\n2. Psychological perspective: From a psychological perspective, the meaning of life is to find fulfillment and happiness. This can be achieved through personal growth, relationships, and experiences that bring joy and satisfaction.\\n3. Social perspective: From a social perspective, the meaning of life is to contribute to the greater good of society. This can be done through work, volunteering, or other forms of service that benefit others.\\n4. Philosophical perspective: From a philosophical perspective, the meaning of life is a question that has been debated by thinkers throughout history. Some have argued that life has no inherent meaning, and that we must create our own purpose and meaning. Others have argued that life has a predetermined meaning or purpose, and that we must discover this through reflection and self-awareness.\\n5. Religious perspective: From a religious perspective, the meaning of life is often seen as derived from a divine source. Many religions teach that the purpose of life is to serve and worship God, or to follow the teachings of a particular faith.\\n6. Existentialist perspective: From an existentialist perspective, the meaning of life is not predetermined or inherent, but rather something that we must create for ourselves. This perspective emphasizes individual freedom and choice, and the idea that we must take responsibility for creating our own meaning in life.\\n7. Humanistic perspective: From a humanistic perspective, the meaning of life is centered on human experience and fulfillment. This perspective emphasizes the importance of personal growth, relationships, and self-actualization.\\n8. Cosmological perspective: From a cosmological perspective, the meaning of life is tied to the nature of the universe and our place in it. Some have argued that life is a rare and precious occurrence in an otherwise vast and empty universe, and that we must make the most of our time here.\\n9. Evolutionary perspective: From an evolutionary perspective, the meaning of life is to survive and evolve as a species. This perspective emphasizes the importance of adaptation, innovation, and progress in the ongoing story of life on Earth.\\n10. Mystical perspective: From a mystical perspective, the meaning of life is to connect with a higher power or ultimate reality. This perspective emphasizes the idea that our lives are part of a larger cosmic whole, and that we must cultivate a deep sense of inner peace and connection to find true meaning.\\nIn conclusion, the meaning of life is a complex and multifaceted question that has been debated by philosophers, theologians, and scientists for centuries. There is no one definitive answer, but rather a variety of perspectives that can help us understand this profound question. Ultimately, the meaning of life may be something that we must each discover for ourselves based on our own experiences, beliefs, and values.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"What's the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's a list of 10 areas of my work as an entry-level Data Scientist that I think will be disrupted by the widespread usage of Large Language Models (LLMs) or tools built on LLMs:\n",
      "1. Data Preprocessing: Many tasks in data preprocessing, such as tokenization, stemming, and lemmatization, can be automated using LLMs. This could make my work more efficient and reduce the time spent on these tasks.\n",
      "2. Feature Engineering: LLMs can help generate new features that can improve model performance. For example, LLMs can be used to generate sentiment scores or topic models for text data. This could lead to better insights and improved accuracy in machine learning models.\n",
      "3. Data Visualization: LLMs can be used to generate interactive visualizations that provide more detailed insights into data. For example, LLMs can be used to create interactive heatmaps or word clouds that show the distribution of words in a dataset.\n",
      "4. Text Summarization: LLMs can be used to summarize long documents or articles into shorter summaries. This could be useful for quickly grasping the main points of a document or article.\n",
      "5. Sentiment Analysis: LLMs can be used to analyze text data and provide sentiment scores. This could be useful for understanding public opinion on a particular topic or product.\n",
      "6. Named Entity Recognition (NER): LLMs can be used to automatically identify and extract named entities such as people, organizations, and locations from text data. This could save time and improve the accuracy of downstream tasks such as information extraction or summarization.\n",
      "7. Part-of-speech Tagging: LLMs can be used to automatically assign part-of-speech tags to words in a sentence. This could improve the accuracy of downstream tasks such as named entity recognition and sentiment analysis.\n",
      "8. Dependency Parsing: LLMs can be used to analyze the grammatical structure of sentences and identify the relationships between words. This could lead to better insights into language usage and improved accuracy in natural language processing tasks.\n",
      "9. Information Extraction: LLMs can be used to automatically extract structured data from unstructured text. For example, LLMs can be used to extract names, dates, and locations from news articles or social media posts.\n",
      "10. Question Answering: LLMs can be used to answer questions based on the content of a document or article. This could be useful for providing quick answers to common customer support queries or for automating content search engines.\n",
      "Overall, the widespread adoption of LLMs and tools built on LLMs has the potential to significantly improve the efficiency and accuracy of many tasks in data science, particularly those involving natural language processing."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2115.84 ms\n",
      "llama_print_timings:      sample time =   545.15 ms /   601 runs   (    0.91 ms per token,  1102.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  7841.22 ms /    44 tokens (  178.21 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:        eval time = 43740.43 ms /   600 runs   (   72.90 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:       total time = 55364.09 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nHere's a list of 10 areas of my work as an entry-level Data Scientist that I think will be disrupted by the widespread usage of Large Language Models (LLMs) or tools built on LLMs:\\n1. Data Preprocessing: Many tasks in data preprocessing, such as tokenization, stemming, and lemmatization, can be automated using LLMs. This could make my work more efficient and reduce the time spent on these tasks.\\n2. Feature Engineering: LLMs can help generate new features that can improve model performance. For example, LLMs can be used to generate sentiment scores or topic models for text data. This could lead to better insights and improved accuracy in machine learning models.\\n3. Data Visualization: LLMs can be used to generate interactive visualizations that provide more detailed insights into data. For example, LLMs can be used to create interactive heatmaps or word clouds that show the distribution of words in a dataset.\\n4. Text Summarization: LLMs can be used to summarize long documents or articles into shorter summaries. This could be useful for quickly grasping the main points of a document or article.\\n5. Sentiment Analysis: LLMs can be used to analyze text data and provide sentiment scores. This could be useful for understanding public opinion on a particular topic or product.\\n6. Named Entity Recognition (NER): LLMs can be used to automatically identify and extract named entities such as people, organizations, and locations from text data. This could save time and improve the accuracy of downstream tasks such as information extraction or summarization.\\n7. Part-of-speech Tagging: LLMs can be used to automatically assign part-of-speech tags to words in a sentence. This could improve the accuracy of downstream tasks such as named entity recognition and sentiment analysis.\\n8. Dependency Parsing: LLMs can be used to analyze the grammatical structure of sentences and identify the relationships between words. This could lead to better insights into language usage and improved accuracy in natural language processing tasks.\\n9. Information Extraction: LLMs can be used to automatically extract structured data from unstructured text. For example, LLMs can be used to extract names, dates, and locations from news articles or social media posts.\\n10. Question Answering: LLMs can be used to answer questions based on the content of a document or article. This could be useful for providing quick answers to common customer support queries or for automating content search engines.\\nOverall, the widespread adoption of LLMs and tools built on LLMs has the potential to significantly improve the efficiency and accuracy of many tasks in data science, particularly those involving natural language processing.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"As an entry-level Data Scientist, what are 10 areas of your work that you think will get disrupted by the widespread usage of LLMs or tools built on LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Although I am an early career pharmacist, and I lack industry expertise as a seasoned professional in the field of pediatrics or AI technology I can imagine several ways that LLMs could disrupt various aspects of my work:\n",
      "1. Medication dosing: One potential area of disruption is medication dosing. LLMs may be able to quickly and accurately determine appropriate drug dosages for children based on their weight, age, and other factors, potentially reducing the need for human intervention and improving medication safety. \n",
      "2.Drug interactions: Another possible area of disruption is the identification of potential drug interactions. LLMs may be able to analyze large amounts of data and identify potential drug interaction that a human pharmacist might miss, helping to prevent adverse events and improve patient outcomes. \n",
      "3. Allergic reactions: With their ability to analyze large amounts of data, LLMs may also be useful in identifying patterns related to allergic reactions, allowing healthcare providers to take proactive steps to prevent these reactions or quickly respond to them if they occur.\n",
      "4. Developmental delays: The use of LLMs could help identify children at risk for developmental delays and provide early interventions that can improve outcomes for those children.\n",
      "5. Pediatric clinical decision support: With the ability to process vast amounts of data, LLMs may be able provide real-time clinical decision support to healthcare providers, improving diagnostic accuracy and reducing errors in patient care.  \n",
      "6. Medical coding and billing: The use of LLMs could improve the accuracy of medical coding and billing, potentially reducing errors and improving reimbursement for healthcare providers. \n",
      "7. Pharmacovigilance: With their ability to analyze large amounts of data, LLMs may also be useful in pharmacovigilance by identifying potential safety issues related to pediatric medication use and allowing healthcare providers to take proactive steps to mitigate these risks.\n",
      "8 Patient education: The use of LLMs could improve patient education, allowing healthcare providers to provide tailored information that addresses the unique needs of each child based on their medical history, allergies, and other factors. \n",
      "9. Referrals and consultations: With the ability to diagnose and treat a wide range of pediatric conditions, LLMs could help identify children who require specialist care or consultation with other healthcare providers, potentially reducing unnecessary referrals and improving patient outcomes.  \n",
      "10. Public health surveillance: Finally, the use of LLMs could improve public health surveillance by analyzing large amounts of data related to pediatric health issues, allowing healthcare providers to identify trends and patterns that can inform population-based interventions and policies. \n",
      "As an early career pharmacist, I recognize that the widespread adoption of LLMs or tools built on these technologies will require significant investment in training and infrastructure, as well as careful consideration of ethical and legal issues related to health data privacy and security.  \n",
      "However, if properly implemented, these technologies have the potential to transform the field of pediatric pharmacology, improving patient outcomes and reducing healthcare costs over time. Despite the challenges ahead, I remain excited about the potential applications of LLMs in pediatric pharmacology practice and look forward to seeing how these developments shape the future of our profession. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2115.84 ms\n",
      "llama_print_timings:      sample time =   706.37 ms /   769 runs   (    0.92 ms per token,  1088.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  7440.91 ms /    44 tokens (  169.11 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:        eval time = 52303.43 ms /   768 runs   (   68.10 ms per token,    14.68 tokens per second)\n",
      "llama_print_timings:       total time = 62987.68 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Although I am an early career pharmacist, and I lack industry expertise as a seasoned professional in the field of pediatrics or AI technology I can imagine several ways that LLMs could disrupt various aspects of my work:\\n1. Medication dosing: One potential area of disruption is medication dosing. LLMs may be able to quickly and accurately determine appropriate drug dosages for children based on their weight, age, and other factors, potentially reducing the need for human intervention and improving medication safety. \\n2.Drug interactions: Another possible area of disruption is the identification of potential drug interactions. LLMs may be able to analyze large amounts of data and identify potential drug interaction that a human pharmacist might miss, helping to prevent adverse events and improve patient outcomes. \\n3. Allergic reactions: With their ability to analyze large amounts of data, LLMs may also be useful in identifying patterns related to allergic reactions, allowing healthcare providers to take proactive steps to prevent these reactions or quickly respond to them if they occur.\\n4. Developmental delays: The use of LLMs could help identify children at risk for developmental delays and provide early interventions that can improve outcomes for those children.\\n5. Pediatric clinical decision support: With the ability to process vast amounts of data, LLMs may be able provide real-time clinical decision support to healthcare providers, improving diagnostic accuracy and reducing errors in patient care.  \\n6. Medical coding and billing: The use of LLMs could improve the accuracy of medical coding and billing, potentially reducing errors and improving reimbursement for healthcare providers. \\n7. Pharmacovigilance: With their ability to analyze large amounts of data, LLMs may also be useful in pharmacovigilance by identifying potential safety issues related to pediatric medication use and allowing healthcare providers to take proactive steps to mitigate these risks.\\n8 Patient education: The use of LLMs could improve patient education, allowing healthcare providers to provide tailored information that addresses the unique needs of each child based on their medical history, allergies, and other factors. \\n9. Referrals and consultations: With the ability to diagnose and treat a wide range of pediatric conditions, LLMs could help identify children who require specialist care or consultation with other healthcare providers, potentially reducing unnecessary referrals and improving patient outcomes.  \\n10. Public health surveillance: Finally, the use of LLMs could improve public health surveillance by analyzing large amounts of data related to pediatric health issues, allowing healthcare providers to identify trends and patterns that can inform population-based interventions and policies. \\nAs an early career pharmacist, I recognize that the widespread adoption of LLMs or tools built on these technologies will require significant investment in training and infrastructure, as well as careful consideration of ethical and legal issues related to health data privacy and security.  \\nHowever, if properly implemented, these technologies have the potential to transform the field of pediatric pharmacology, improving patient outcomes and reducing healthcare costs over time. Despite the challenges ahead, I remain excited about the potential applications of LLMs in pediatric pharmacology practice and look forward to seeing how these developments shape the future of our profession. '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=\"\"\"\n",
    "As an entry-level Pediatric Pharmacist, what are 10 areas of your work that you think will get disrupted by the widespread usage of LLMs or tools built on LLMs?\n",
    "\"\"\"\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get LLM risks for all titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = pd.read_csv(\"../data/df_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>pluralName</th>\n",
       "      <th>isSupervisor</th>\n",
       "      <th>levelBand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ET4A446A1A5F6142AD</td>\n",
       "      <td>.NET Application Architect</td>\n",
       "      <td>.NET Application Architects</td>\n",
       "      <td>False</td>\n",
       "      <td>Professional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                        name  \\\n",
       "0  ET4A446A1A5F6142AD  .NET Application Architect   \n",
       "\n",
       "                    pluralName  isSupervisor     levelBand  \n",
       "0  .NET Application Architects         False  Professional  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "While I am not aware of any direct evidence of widespread usage of LLMs in the field of President/Artistic Director, here are 10 possible areas where LLMs could have a significant impact:\n",
      "1. Casting Decisions: LLMs could analyze vast amounts of data on actor performance, ratings, and box office results to help Presidents/Artistic Directors make informed casting decisions.\n",
      "2. Script Development: LLMs could assist in the development of screenplays by analyzing and generating ideas based on market trends, audience preferences, and successful precedents.\n",
      "3. Set Design: LLMs could analyze design concepts and generate new ideas for set design based on previous successful productions and artistic preferences.\n",
      "4. Marketing Strategies: LLMs could help identify and target specific demographics, analyize market trends, and predict the success of marketing campaigns.\n",
      "5. Fundraising Efforts: LLMs could analyze giving patterns and predict potential donation amounts to assist in fundraising efforts.\n",
      "6. Budget Planning: LLMs could help Presidents/Artistic Directors create realistic budgets based on historical spending data, market trends, and artistic preferences.\n",
      "7. Legal Compliance: LLMs could analyze legal agreements and contracts to ensure that the company is compliant with all relevant laws and regulations.\n",
      "8. Community Outreach: LLMs could help identify and target specific communities for outreach efforts based on demographic analysis and market trends.\n",
      "9. Audience Engagement: LLMs could analyze audience engagement data to help Presidents/Artistic Directors make informed decisions about programming and community outreach.\n",
      "10. Strategic Planning: LLMs could assist in strategic planning by analyzing market trends, identifying potential risks and opportunities, and providing recommendations based on data-driven insights."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2115.84 ms\n",
      "llama_print_timings:      sample time =   380.94 ms /   429 runs   (    0.89 ms per token,  1126.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  8904.59 ms /    41 tokens (  217.19 ms per token,     4.60 tokens per second)\n",
      "llama_print_timings:        eval time = 28873.21 ms /   428 runs   (   67.46 ms per token,    14.82 tokens per second)\n",
      "llama_print_timings:       total time = 40347.63 ms\n",
      " 50%|█████     | 1/2 [00:40<00:40, 40.36s/it]Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As an entry-level Director of Medical Surgical Services, I foresee significant disruptions in my work with the widespread use of large language models (LLMs) or tools built on LLMs. Here are 10 areas that could be impacted:\n",
      "1. Clinical Decision Support: With LLMs' ability to analyze vast amounts of medical literature, they could become a go-to resource for clinicians in need of quick and accurate decision-making support, potentially reducing the need for experienced clinicians to make certain judgments.\n",
      "2. Medical Billing and Coding: LLMs can quickly process and accurately code medical records and generate billing information, streamlining administrative tasks and reducing errors.\n",
      "3. Patient Communication: AI-powered tools could automate patient communication, such as appointment reminders, prescription refill requests, and post-procedure instructions, freeing up staff time for more critical tasks.\n",
      "4. Supply Chain Management: With LLMs' ability to analyze trends and patterns in medical supply usage, they could optimize inventory management and reduce waste, saving hospitals resources and money.\n",
      "5. Quality Improvement: AI-powered tools can track patient outcomes and identify areas for improvement, helping healthcare providers make data-driven decisions to enhance the quality of care.\n",
      "6. Provider Training and Credentialing: LLMs can analyze extensive medical literature and provide personalized training recommendations for physicians, helping them improve their skills and stay up-to-date with the latest medical knowledge.\n",
      "7. Medical Research Collaboration: With AI-powered tools that facilitate collaboration across healthcare providers, researchers, and institutions, LLMs can enable more efficient and effective coordination of international medical projects.\n",
      "8. Real-time Clinical Analytics: By analyzing vast amounts of data in real time, LLMs can provide immediate insights into patient populations, allowing for proactive care management and strategic planning.\n",
      "9. Virtual Assistants for Patients: AI-powered virtual assistants can help patients navigate the healthcare system, answer medical questions, and even schedule appointments or fill prescriptions electronically.\n",
      "10. Clinical Trials Participation: By identifying potential trial participants based on electronic medical records and other data sources, LLMs can help researchers streamline clinical trial recruitment and enrollment processes, reducing the time and cost associated with traditional methods.\n",
      "These areas represent just a few examples of how AI-powered tools built on LLMs could disrupt entry-level Director of Medical Surgical Services' work in the healthcare industry. As these technologies continue to evolve, it is crucial for me as an entry-level Director to stay ahead of the curve and prepare for the transformative impact they will have on my role and responsibilities."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2115.84 ms\n",
      "llama_print_timings:      sample time =   611.21 ms /   635 runs   (    0.96 ms per token,  1038.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4799.41 ms /    43 tokens (  111.61 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:        eval time = 40711.69 ms /   634 runs   (   64.21 ms per token,    15.57 tokens per second)\n",
      "llama_print_timings:       total time = 48173.42 ms\n",
      "100%|██████████| 2/2 [01:28<00:00, 44.27s/it]\n"
     ]
    }
   ],
   "source": [
    "list_titles_llm_risk = []\n",
    "\n",
    "for index, row in tqdm(df_titles.sample(2).iterrows(), total=len(df_titles.head(2))):\n",
    "    TITLE=row['name']\n",
    "    prompt=f\"\"\"As an entry-level {TITLE}, what are 10 areas of your work that you think will get disrupted by the widespread usage of LLMs or tools built on LLMs?\"\"\"\n",
    "    llm_generation = llm(prompt)\n",
    "\n",
    "    # store title and generation as a dict\n",
    "    llm_risk_dict = {\n",
    "        \"title\": TITLE,\n",
    "        \"generation\": llm_generation\n",
    "    }\n",
    "\n",
    "    # append to list\n",
    "    list_titles_llm_risk.append(llm_risk_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 0,\n",
       "  'generation': '\\nI can provide my perspective as an entry-level linguist. Here are ten potential areas of my work that could be disrupted by the widespread usage of large language models (LLMs) or tools built on LLMs:\\n1. Language Translation: With the ability to generate human-like text, LLMs could potentially automate language translation tasks with high accuracy, making human translators redundant.\\n2. Content Creation: LLMs can generate content in various formats, including articles, blog posts, and social media updates. This could disrupt the work of content creators, especially those who rely on formulaic writing.\\n3. Copy Editing and Proofreading: AI-powered tools built on LLMs could automate copy editing and proofreading tasks with high accuracy, potentially making human editors redundant.\\n4. Language Localization: With the ability to generate translated text in various languages, LLMs could disrupt the language localization industry by providing high-quality translations at a lower cost.\\n5. Text Summarization: LLMs can summarize long pieces of text into shorter, more digestible versions. This could disrupt the work of content curators and summarizers.\\n6. Sentiment Analysis: AI-powered tools built on LLMs could automate sentiment analysis tasks with high accuracy, potentially making human analysts redundant.\\n7. Named Entity Recognition (NER): LLMs can extract named entities such as people, organizations, and locations from text. This could disrupt the work of data annotators and NER specialists.\\n8. Question Answering: With the ability to generate human-like text, LLMs could potentially automate question answering tasks with high accuracy, making human Q&A experts redundant.\\n9. Text Generation for Chatbots and Virtual Assistants: LLMs can generate human-like text in real-time, which could disrupt the work of chatbot and virtual assistant developers who rely on pre-written responses.\\n10. Content Curation: AI-powered tools built on LLMs could automate content curation tasks by identifying and extracting relevant information from vast amounts of text data. This could potentially disrupt the work of human curators and researchers.'},\n",
       " {'title': 1,\n",
       "  'generation': \"\\nI'm looking for practical and specific examples of tasks or aspects of your job that you think will see significant changes.\\n\\nPlease provide concrete examples of how these tasks might be affected, and what kind of skills or knowledge will be required to perform them in the future.\\n\\nHere are ten potential areas where I think AI-driven LLMs will have a significant impact on my work as an entry-level 1:\\n\\n1. Data Analysis: As LLMs become more sophisticated, they will be able to extract insights from large datasets much faster and more accurately than humans can. This will change the nature of data analysis tasks, requiring new skills in areas such as data preparation, model evaluation, and result interpretation.\\n2. Report Writing: LLMs will be able to generate high-quality reports based on data analysis, freeing up human analysts to focus on higher-level tasks such as strategic planning and decision-making. However, this will require a shift in skillset towards crafting clear, concise narratives that can effectively communicate findings to stakeholders.\\n3. Content Creation: LLMs will be able to generate content based on existing data and knowledge, reducing the need for human copywriters and journalists. However, this will also create new opportunities for creative professionals who can learn to work with AI tools to generate innovative and engaging content.\\n4. Customer Support: LLMs will be able to answer routine customer inquiries, freeing up human support agents to focus on more complex issues that require empathy and emotional intelligence. This will require a shift in skillset towards developing strong diplomacy and conflict resolution skills.\\n5. Predictive Modeling: As LLMs become more sophisticated, they will be able to build predictive models that are much more accurate than those built by humans today. However, this will also require human analysts to develop new skills in areas such as model evaluation, feature engineering, and data preprocessing.\\n6. Information Architecture: As the volume of digital content continues to growth, LLMs will be essential for organizing and categorizing information in meaningful ways. This will require a new skillset in information architecture, as well as an understanding of how AI algorithms work.\\n7. Content Moderation: LLMs will be able to automatically identify and remove harmful or inappropriate content from online platforms, reducing the need for human moderators. However, this will also require a shift in skillset towards developing expertise in areas such as bias, fairness, and ethics in AI systems.\\n8. Personalized Recommendations: LLMs will be able to provide personalized recommendations to users based on their preferences, behavior, and interests. This will create new opportunities for professionals who can develop algorithms that take into account ethical considerations around privacy, bias, and addiction.\\n9. Event Planning: LLMs will be able to automatically generate event plans and customized itineraries based on preferences and constraints, freeing up human organizers to focus on high-level creative tasks such as theme development and logistics management. However, this will also require a shift in skillset towards developing expertise in areas such as project management and supply chain logistics.\\n10. Translation Services: LLMs will be able to provide real-time machine translation services that are much more accurate and efficient than those provided by human translators today. However, this will also require a shift in skillset towards developing expertise in areas such as language teaching, cultural competency, and multilingual communication.\\nIn summary, my work as an entry-level 1 will be significantly impacted by the widespread usage of LLMs and tools built on LLMs, but the specific skills and knowledge required to perform these tasks effectively will also change in exciting and unexpected ways. I'm looking forward to adapting my skillset towards these emerging areas of need!\"}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_titles_llm_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on all onet titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onet_titles = pd.read_excel(\"../data/db_27_3_excel/Occupation Data.xlsx\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Determine and formulate policies and provide o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.03</td>\n",
       "      <td>Chief Sustainability Officers</td>\n",
       "      <td>Communicate and coordinate with management, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1021.00</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>Plan, direct, or coordinate the operations of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1031.00</td>\n",
       "      <td>Legislators</td>\n",
       "      <td>Develop, introduce, or enact laws and statutes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-2011.00</td>\n",
       "      <td>Advertising and Promotions Managers</td>\n",
       "      <td>Plan, direct, or coordinate advertising polici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code                                Title  \\\n",
       "0     11-1011.00                     Chief Executives   \n",
       "1     11-1011.03        Chief Sustainability Officers   \n",
       "2     11-1021.00      General and Operations Managers   \n",
       "3     11-1031.00                          Legislators   \n",
       "4     11-2011.00  Advertising and Promotions Managers   \n",
       "\n",
       "                                         Description  \n",
       "0  Determine and formulate policies and provide o...  \n",
       "1  Communicate and coordinate with management, sh...  \n",
       "2  Plan, direct, or coordinate the operations of ...  \n",
       "3  Develop, introduce, or enact laws and statutes...  \n",
       "4  Plan, direct, or coordinate advertising polici...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onet_titles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onet_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/lawrence.wu/Documents/github/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: mem required  = 7349.72 MB (+ 1600.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 1600.00 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: using MPS\n",
      "ggml_metal_init: loading '/Users/lawrence.wu/Documents/github/research-llms/venv/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x155fffc80\n",
      "ggml_metal_init: loaded kernel_add_row                        0x2831f62b0\n",
      "ggml_metal_init: loaded kernel_mul                            0x2831f6bb0\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x1171b0de0\n",
      "ggml_metal_init: loaded kernel_scale                          0x2831f74b0\n",
      "ggml_metal_init: loaded kernel_silu                           0x157704a00\n",
      "ggml_metal_init: loaded kernel_relu                           0x1171b10c0\n",
      "ggml_metal_init: loaded kernel_gelu                           0x2831f7a80\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x2831f7ce0\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x2831f7f40\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x2831f0ce0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x2831f81b0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x2831f8410\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x2831f8670\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x2831f88d0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x2831f8b30\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x2831f8d90\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x2831f8ff0\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x2831f9250\n",
      "ggml_metal_init: loaded kernel_norm                           0x2831f94b0\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x2831f9710\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x2831f9970\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x2831f9bd0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x2831f9e30\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x2831fa090\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x2831fa2f0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x2831fa550\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x2831fa7b0\n",
      "ggml_metal_init: loaded kernel_rope                           0x2831faa10\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x2831fac70\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x2831faed0\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x2831fb130\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x2831fb390\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 21845.34 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "llama_new_context_with_model: max tensor size =    87.89 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  6984.06 MB, (24890.94 / 21845.34), warning: current allocated size is greater than the recommended max working set size\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =    12.00 MB, (24902.94 / 21845.34), warning: current allocated size is greater than the recommended max working set size\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1602.00 MB, (26504.94 / 21845.34), warning: current allocated size is greater than the recommended max working set size\n",
      "ggml_metal_add_buffer: allocated 'scr0            ' buffer, size =   162.00 MB, (26666.94 / 21845.34), warning: current allocated size is greater than the recommended max working set size\n",
      "ggml_metal_add_buffer: allocated 'scr1            ' buffer, size =   192.00 MB, (26858.94 / 21845.34), warning: current allocated size is greater than the recommended max working set size\n"
     ]
    }
   ],
   "source": [
    "llm_no_verbose = LlamaCpp(\n",
    "            model_path=f\"/Users/lawrence.wu/Documents/github/llama.cpp/{MODEL_LLAMA2_13B}\",\n",
    "            temperature=1,\n",
    "            top_p=1,\n",
    "            max_tokens=2048,\n",
    "            n_ctx=2048,\n",
    "            n=-1,\n",
    "            repeat_penalty=1.1,\n",
    "            n_threads=8,\n",
    "            # callback_manager=callback_manager,\n",
    "            n_gpu_layers=n_gpu_layers,\n",
    "            n_batch=2048,  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "            f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "            verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 731/1016 [10:02:49<3:55:01, 49.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m TITLE\u001b[39m=\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mTitle\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m prompt\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mAs a \u001b[39m\u001b[39m{\u001b[39;00mTITLE\u001b[39m}\u001b[39;00m\u001b[39m, what are 10 areas of your work that you think will get disrupted by the widespread usage of LLMs or tools built on LLMs?\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m llm_generation \u001b[39m=\u001b[39m llm_no_verbose(prompt)\n\u001b[1;32m      8\u001b[0m \u001b[39m# store title and generation as a dict\u001b[39;00m\n\u001b[1;32m      9\u001b[0m llm_risk_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: TITLE,\n\u001b[1;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgeneration\u001b[39m\u001b[39m\"\u001b[39m: llm_generation\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     12\u001b[0m }\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/llms/base.py:427\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(prompt, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    421\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(prompt)\u001b[39m}\u001b[39;00m\u001b[39m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`generate` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 427\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    428\u001b[0m         [prompt],\n\u001b[1;32m    429\u001b[0m         stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    430\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    431\u001b[0m         tags\u001b[39m=\u001b[39;49mtags,\n\u001b[1;32m    432\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    433\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m     \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    436\u001b[0m     \u001b[39m.\u001b[39mtext\n\u001b[1;32m    437\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/llms/base.py:279\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    274\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m         )\n\u001b[1;32m    276\u001b[0m     run_managers \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    277\u001b[0m         dumpd(\u001b[39mself\u001b[39m), prompts, invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[1;32m    278\u001b[0m     )\n\u001b[0;32m--> 279\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    280\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/llms/base.py:223\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    222\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    224\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    225\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/llms/base.py:210\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    202\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    207\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    208\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 210\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    211\u001b[0m                 prompts,\n\u001b[1;32m    212\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    213\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    214\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    215\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    216\u001b[0m             )\n\u001b[1;32m    217\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    218\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    219\u001b[0m         )\n\u001b[1;32m    220\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    221\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/llms/base.py:602\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    600\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m    601\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 602\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    603\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    604\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m    607\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/llms/llamacpp.py:230\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[1;32m    226\u001b[0m     \u001b[39m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[39m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     combined_text_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream(prompt\u001b[39m=\u001b[39mprompt, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager):\n\u001b[1;32m    231\u001b[0m         combined_text_output \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m token[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/llms/llamacpp.py:280\u001b[0m, in \u001b[0;36mLlamaCpp.stream\u001b[0;34m(self, prompt, stop, run_manager)\u001b[0m\n\u001b[1;32m    278\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_parameters(stop)\n\u001b[1;32m    279\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient(prompt\u001b[39m=\u001b[39mprompt, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m--> 280\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m result:\n\u001b[1;32m    281\u001b[0m     token \u001b[39m=\u001b[39m chunk[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    282\u001b[0m     log_probs \u001b[39m=\u001b[39m chunk[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/llama_cpp/llama.py:899\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor)\u001b[0m\n\u001b[1;32m    897\u001b[0m finish_reason \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    898\u001b[0m multibyte_fix \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 899\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(\n\u001b[1;32m    900\u001b[0m     prompt_tokens,\n\u001b[1;32m    901\u001b[0m     top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m    902\u001b[0m     top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[1;32m    903\u001b[0m     temp\u001b[39m=\u001b[39mtemperature,\n\u001b[1;32m    904\u001b[0m     tfs_z\u001b[39m=\u001b[39mtfs_z,\n\u001b[1;32m    905\u001b[0m     mirostat_mode\u001b[39m=\u001b[39mmirostat_mode,\n\u001b[1;32m    906\u001b[0m     mirostat_tau\u001b[39m=\u001b[39mmirostat_tau,\n\u001b[1;32m    907\u001b[0m     mirostat_eta\u001b[39m=\u001b[39mmirostat_eta,\n\u001b[1;32m    908\u001b[0m     frequency_penalty\u001b[39m=\u001b[39mfrequency_penalty,\n\u001b[1;32m    909\u001b[0m     presence_penalty\u001b[39m=\u001b[39mpresence_penalty,\n\u001b[1;32m    910\u001b[0m     repeat_penalty\u001b[39m=\u001b[39mrepeat_penalty,\n\u001b[1;32m    911\u001b[0m     stopping_criteria\u001b[39m=\u001b[39mstopping_criteria,\n\u001b[1;32m    912\u001b[0m     logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[1;32m    913\u001b[0m ):\n\u001b[1;32m    914\u001b[0m     \u001b[39mif\u001b[39;00m token \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token_eos:\n\u001b[1;32m    915\u001b[0m         text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetokenize(completion_tokens)\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/llama_cpp/llama.py:721\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, logits_processor, stopping_criteria)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    720\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval(tokens)\n\u001b[1;32m    722\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(\n\u001b[1;32m    723\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m    724\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    733\u001b[0m         logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[1;32m    734\u001b[0m     )\n\u001b[1;32m    735\u001b[0m     \u001b[39mif\u001b[39;00m stopping_criteria \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m stopping_criteria(\n\u001b[1;32m    736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_ids\u001b[39m.\u001b[39mtolist(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scores[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    737\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/llama_cpp/llama.py:461\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    459\u001b[0m n_past \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_ctx \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(batch), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_ids))\n\u001b[1;32m    460\u001b[0m n_tokens \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch)\n\u001b[0;32m--> 461\u001b[0m return_code \u001b[39m=\u001b[39m llama_cpp\u001b[39m.\u001b[39;49mllama_eval(\n\u001b[1;32m    462\u001b[0m     ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx,\n\u001b[1;32m    463\u001b[0m     tokens\u001b[39m=\u001b[39;49m(llama_cpp\u001b[39m.\u001b[39;49mllama_token \u001b[39m*\u001b[39;49m \u001b[39mlen\u001b[39;49m(batch))(\u001b[39m*\u001b[39;49mbatch),\n\u001b[1;32m    464\u001b[0m     n_tokens\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(n_tokens),\n\u001b[1;32m    465\u001b[0m     n_past\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(n_past),\n\u001b[1;32m    466\u001b[0m     n_threads\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_threads),\n\u001b[1;32m    467\u001b[0m )\n\u001b[1;32m    468\u001b[0m \u001b[39mif\u001b[39;00m return_code \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    469\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mllama_eval returned \u001b[39m\u001b[39m{\u001b[39;00mreturn_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/llama_cpp/llama_cpp.py:678\u001b[0m, in \u001b[0;36mllama_eval\u001b[0;34m(ctx, tokens, n_tokens, n_past, n_threads)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mllama_eval\u001b[39m(\n\u001b[1;32m    672\u001b[0m     ctx: llama_context_p,\n\u001b[1;32m    673\u001b[0m     tokens,  \u001b[39m# type: Array[llama_token]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     n_threads: c_int,\n\u001b[1;32m    677\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 678\u001b[0m     \u001b[39mreturn\u001b[39;00m _lib\u001b[39m.\u001b[39;49mllama_eval(ctx, tokens, n_tokens, n_past, n_threads)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_onet_titles_llm_risk = []\n",
    "\n",
    "for index, row in tqdm(df_onet_titles.iterrows(), total=len(df_onet_titles)):\n",
    "    TITLE=row['Title']\n",
    "    prompt=f\"\"\"As a {TITLE}, what are 10 areas of your work that you think will get disrupted by the widespread usage of LLMs or tools built on LLMs?\"\"\"\n",
    "    llm_generation = llm_no_verbose(prompt)\n",
    "\n",
    "    # store title and generation as a dict\n",
    "    llm_risk_dict = {\n",
    "        \"title\": TITLE,\n",
    "        \"generation\": llm_generation.strip()\n",
    "    }\n",
    "\n",
    "    # append to list\n",
    "    list_onet_titles_llm_risk.append(llm_risk_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Financial Risk Specialist, I have identified the following 10 areas where the widespread usage of large language models (LLMs) or tools built on LLMs could potentially disrupt my work:\n",
      "1. Credit risk assessment: LLMs could improve credit risk assessment by analyzing vast amounts of financial data to identify patterns and predict future credit events. This could lead to more accurate and efficient credit risk assessments, potentially reducing the need for human analysts.\n",
      "2. Fraud detection: LLMs could be trained on historical fraud data to identify patterns and anomalies that indicate potential fraudulent activity. This could help financial institutions detect fraud earlier and with greater accuracy, reducing financial losses.\n",
      "3. Compliance monitoring: LLMs could be used to monitor compliance with financial regulations, such as Anti-Money Laundering (AML) and Know Your Customer (KYC) requirements. This could help identify potential regulatory violations more effectively and efficiently than human analysts.\n",
      "4. Portfolio analysis: LLMs could analyze large amounts of financial data to provide insights on portfolio performance, risk exposure, and investment opportunities. This could potentially disrupt the traditional asset management industry by providing low-cost, algorithmic investment strategies.\n",
      "5. Market sentiment analysis: LLMs could be trained on social media and other text data to analyze market sentiment and predict future market trends. This could provide more accurate and timely investment insights than traditional methods of analyzing market trends.\n",
      "6. Credit risk quantification: LLMs could help quantify credit risk by analyzing large amounts of financial data to estimate the probability of default and expected loss. This could lead to more accurate credit pricing and risk management practices.\n",
      "7. Loan review automation: LLMs could be used to automate loan review processes, such as identifying potential fraud or compliance issues in loan applications. This could help reduce manual effort and improve the accuracy and efficiency of loan review processes.\n",
      "8. Risk modeling: LLMs could be used to build more sophisticated risk models that incorporate a wide range of data sources and factors. This could lead to more accurate risk assessments and better decision-making by financial institutions.\n",
      "9. Liquidity analysis: LLMs could analyze large amounts of financial data to provide insights on market liquidity and identify potential liquidity risks. This could help financial institutions better manage liquidity risk and improve their overall risk management practices.\n",
      "10. Regulatory reporting: LLMs could be used to automate regulatory reporting processes, such as generating reports required by financial regulations like Basel III or Solvency II. This could help reduce manual effort and improve the accuracy and efficiency of regulatory reporting processes.\n",
      "Overall, the widespread usage of LLMs or tools built on LLMs could potentially disrupt many aspects of my work as a Financial Risk Specialist, leading to more accurate risk assessments, better decision-making, and more efficient financial management practices. However, it also presents challenges such as data quality issues, potential biases in the models, and the need for ongoing model improvement and updates.\n"
     ]
    }
   ],
   "source": [
    "print(list_onet_titles_llm_risk[100]['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_onet_titles_llm_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import json\n",
    "# write to pickle\n",
    "\n",
    "# with open('../data/list_onet_titles_llm_risk.pkl', 'wb') as f:\n",
    "#     pickle.dump(list_onet_titles_llm_risk, f)\n",
    "\n",
    "# convert list_onet_titles_llm_risk to json and dumps\n",
    "out = json.dumps(list_onet_titles_llm_risk, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write json out to disk\n",
    "with open('../data/list_onet_titles_llm_risk.json', 'w') as outfile:\n",
    "    json.dump(out, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>47-2132.00</td>\n",
       "      <td>Insulation Workers, Mechanical</td>\n",
       "      <td>Apply insulating materials to pipes or ductwor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    O*NET-SOC Code                           Title  \\\n",
       "730     47-2132.00  Insulation Workers, Mechanical   \n",
       "\n",
       "                                           Description  \n",
       "730  Apply insulating materials to pipes or ductwor...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 2\n",
    "df_onet_titles.query(\"Title == 'Insulation Workers, Mechanical'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>47-2141.00</td>\n",
       "      <td>Painters, Construction and Maintenance</td>\n",
       "      <td>Paint walls, equipment, buildings, bridges, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>47-2142.00</td>\n",
       "      <td>Paperhangers</td>\n",
       "      <td>Cover interior walls or ceilings of rooms with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>47-2151.00</td>\n",
       "      <td>Pipelayers</td>\n",
       "      <td>Lay pipe for storm or sanitation sewers, drain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>47-2152.00</td>\n",
       "      <td>Plumbers, Pipefitters, and Steamfitters</td>\n",
       "      <td>Assemble, install, alter, and repair pipelines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>47-2152.04</td>\n",
       "      <td>Solar Thermal Installers and Technicians</td>\n",
       "      <td>Install or repair solar energy systems designe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>55-3014.00</td>\n",
       "      <td>Artillery and Missile Crew Members</td>\n",
       "      <td>Target, fire, and maintain weapons used to des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>55-3015.00</td>\n",
       "      <td>Command and Control Center Specialists</td>\n",
       "      <td>Operate and monitor communications, detection,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>55-3016.00</td>\n",
       "      <td>Infantry</td>\n",
       "      <td>Operate weapons and equipment in ground combat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>55-3018.00</td>\n",
       "      <td>Special Forces</td>\n",
       "      <td>Implement unconventional operations by air, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>55-3019.00</td>\n",
       "      <td>Military Enlisted Tactical Operations and Air/...</td>\n",
       "      <td>All military enlisted tactical operations and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     O*NET-SOC Code                                              Title  \\\n",
       "731      47-2141.00             Painters, Construction and Maintenance   \n",
       "732      47-2142.00                                       Paperhangers   \n",
       "733      47-2151.00                                         Pipelayers   \n",
       "734      47-2152.00            Plumbers, Pipefitters, and Steamfitters   \n",
       "735      47-2152.04           Solar Thermal Installers and Technicians   \n",
       "...             ...                                                ...   \n",
       "1011     55-3014.00                 Artillery and Missile Crew Members   \n",
       "1012     55-3015.00             Command and Control Center Specialists   \n",
       "1013     55-3016.00                                           Infantry   \n",
       "1014     55-3018.00                                     Special Forces   \n",
       "1015     55-3019.00  Military Enlisted Tactical Operations and Air/...   \n",
       "\n",
       "                                            Description  \n",
       "731   Paint walls, equipment, buildings, bridges, an...  \n",
       "732   Cover interior walls or ceilings of rooms with...  \n",
       "733   Lay pipe for storm or sanitation sewers, drain...  \n",
       "734   Assemble, install, alter, and repair pipelines...  \n",
       "735   Install or repair solar energy systems designe...  \n",
       "...                                                 ...  \n",
       "1011  Target, fire, and maintain weapons used to des...  \n",
       "1012  Operate and monitor communications, detection,...  \n",
       "1013  Operate weapons and equipment in ground combat...  \n",
       "1014  Implement unconventional operations by air, la...  \n",
       "1015  All military enlisted tactical operations and ...  \n",
       "\n",
       "[285 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onet_titles[731:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [3:50:48<00:00, 48.59s/it]  \n"
     ]
    }
   ],
   "source": [
    "list_onet_titles_llm_risk_p2 = []\n",
    "\n",
    "for index, row in tqdm(df_onet_titles[731:].iterrows(), total=len(df_onet_titles[731:])):\n",
    "    TITLE=row['Title']\n",
    "    prompt=f\"\"\"As a {TITLE}, what are 10 areas of your work that you think will get disrupted by the widespread usage of LLMs or tools built on LLMs?\"\"\"\n",
    "    llm_generation = llm_no_verbose(prompt)\n",
    "\n",
    "    # store title and generation as a dict\n",
    "    llm_risk_dict = {\n",
    "        \"title\": TITLE,\n",
    "        \"generation\": llm_generation.strip()\n",
    "    }\n",
    "\n",
    "    # append to list\n",
    "    list_onet_titles_llm_risk_p2.append(llm_risk_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_p2 = json.dumps(list_onet_titles_llm_risk_p2, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write json out to disk\n",
    "with open('../data/list_onet_titles_llm_risk_p2.json', 'w') as outfile:\n",
    "    json.dump(out_p2, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine previous two files\n",
    "list_onet_titles_llm_risk_all = list_onet_titles_llm_risk + list_onet_titles_llm_risk_p2\n",
    "len(list_onet_titles_llm_risk_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all = json.dumps(list_onet_titles_llm_risk_all, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write json out to disk\n",
    "with open('../data/list_onet_titles_llm_risk_all.json', 'w') as outfile:\n",
    "    json.dump(out_all, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in json file as a list of dictionaries\n",
    "with open('../data/list_onet_titles_llm_risk_all.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_onet_titles_llm_risk_all = json.loads(data)\n",
    "# list_onet_titles_llm_risk_all[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Determine and formulate policies and provide o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code             Title  \\\n",
       "0     11-1011.00  Chief Executives   \n",
       "\n",
       "                                         Description  \n",
       "0  Determine and formulate policies and provide o...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onet_titles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>15-1242.00</td>\n",
       "      <td>Database Administrators</td>\n",
       "      <td>Administer, test, and implement computer datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>15-1243.00</td>\n",
       "      <td>Database Architects</td>\n",
       "      <td>Design strategies for enterprise databases, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>15-1243.01</td>\n",
       "      <td>Data Warehousing Specialists</td>\n",
       "      <td>Design, model, or implement corporate data war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>15-2051.02</td>\n",
       "      <td>Clinical Data Managers</td>\n",
       "      <td>Apply knowledge of health care and database ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>43-9021.00</td>\n",
       "      <td>Data Entry Keyers</td>\n",
       "      <td>Operate data entry device, such as keyboard or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    O*NET-SOC Code                         Title  \\\n",
       "117     15-1242.00       Database Administrators   \n",
       "118     15-1243.00           Database Architects   \n",
       "119     15-1243.01  Data Warehousing Specialists   \n",
       "142     15-2051.00               Data Scientists   \n",
       "144     15-2051.02        Clinical Data Managers   \n",
       "685     43-9021.00             Data Entry Keyers   \n",
       "\n",
       "                                           Description  \n",
       "117  Administer, test, and implement computer datab...  \n",
       "118  Design strategies for enterprise databases, da...  \n",
       "119  Design, model, or implement corporate data war...  \n",
       "142  Develop and implement a set of techniques or a...  \n",
       "144  Apply knowledge of health care and database ma...  \n",
       "685  Operate data entry device, such as keyboard or...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onet_titles[df_onet_titles['Title'].str.contains(\"Data\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    O*NET-SOC Code            Title  \\\n",
       "142     15-2051.00  Data Scientists   \n",
       "\n",
       "                                           Description  \n",
       "142  Develop and implement a set of techniques or a...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onet_titles.query(\"Title == 'Data Scientists'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 142\n",
      "Title: Data Scientists\n",
      "Description: Below are ten potential areas of my work as a data scientist that could be impacted by the widespread adoption of large language models (LLMs) or tools built upon them:\n",
      "1. Data preparation and cleaning: With LLMs' ability to process and generate text, they could assist in data preparation and cleaning tasks such as sentiment analysis, text classification, entity extraction, etc. Could potentially reduce the time spent on these tasks by human data scientists.\n",
      "2. Feature engineering: LLMs can be used to generate new features or transform existing ones, which could lead to more accurate models and faster development cycles.\n",
      "3. Model interpretation: LLMs can be used to generate insights and explanations for model predictions, which could help better understand how the models work and aid in decision-making.\n",
      "4. Data visualization: LLMs can be used to generate high-quality visualizations of data, automating the process and potentially leading to more sophisticated and accurate visualizations than before.\n",
      "5. Hypothesis generation: LLMs could assist in generating hypotheses based on data patterns, potentially leading to new discoveries and insights that would otherwise be difficult or impossible to find.\n",
      "6. Explanatory modeling: LLMs could generate explanations for complex models like neural networks, allowing for more transparent and interpretable modeling.\n",
      "7. Automated machine learning: LLMs could be used to automate many aspects of the machine learning workflow, such as feature selection, hyperparameter tuning, and model selection, which could significantly speed up the development process.\n",
      "8. Natural Language Processing (NLP): As LLMs are trained on vast amounts of text data, they can potentially revolutionize NLP tasks such as text generation, question answering, sentiment analysis, and more. This could lead to significant progress in areas like chatbots, voice assistants, and other applications that rely on human language understanding.\n",
      "9. Active learning: LLMs could be used to selectively sample the most informative data points for human annotation, potentially leading to faster and more accurate machine learning development.\n",
      "10. Explainable AI (XAI): LLMs can be used to generate explanations for model predictions and assist in developing XAI techniques that are more transparent, interpretable, and accountable. This could lead to more widespread adoption of AI systems in high-stakes applications like healthcare, finance, and government.\n"
     ]
    }
   ],
   "source": [
    "# index = np.random.choice(142)\n",
    "index=142\n",
    "print(f\"Index: {index}\")\n",
    "print(f\"Title: {list_onet_titles_llm_risk_all[index]['title']}\")\n",
    "print(f\"Description: {list_onet_titles_llm_risk_all[index]['generation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 717\n",
      "Title: Floor Sanders and Finishers\n",
      "Description: * 1. Adhesion: With the ability to predict and simulate material behavior, the need for manual testing and quality control may be reduced or eliminated.\n",
      "  * 2. Sanding and Finishing: AI-powered sanders and finishers could improve the efficiency and effectiveness of these processes by optimizing the amount of material removed and the type of finish used.\n",
      "  * 3. Tool Life: Optimized toolpaths and tool life predictions can extend the lifespan of sanding and finishing tools, reducing waste and increasing productivity.\n",
      "  * 4. Material Characterization: LLMs could help identify optimal sanding and finishing techniques for specific materials based on their properties and behaviors.\n",
      "  * 5. Process Optimization: AI-powered systems can analyze data from past projects to optimize future processes, reducing the need for manual trial and error.\n",
      "  * 6. Quality Control: LLMs can assist in predicting and preventing defects, reducing the need for manual inspection and rework.\n",
      "  * 7. Material Wastage Prediction: By simulating material behavior and optimizing toolpaths, LLMs can help predict material wastage and reduce waste.\n",
      "  * 8. Automated Workflows: AI-powered systems can automate sanding and finishing workflows, freeing up workers to focus on higher-value tasks.\n",
      "  *  * Repetitive Tasks: LLMs can automate repetitive tasks such as data entry, documentation, or scheduling, improving productivity and reducing errors.\n",
      "  * 10. Predictive Maintenance: By analyzing sensor data from machines and predicting wear and tear, LLMs can help schedule maintenance and reduce downtime.\n",
      "LLMs have the potential to revolutionize the work of Floor Sanders and Finishers by increasing productivity, reducing waste, and improving the quality of finished products. However, it is important to address any ethical or socioeconomic implications that may arise from these advancements.\n"
     ]
    }
   ],
   "source": [
    "index = np.random.choice(len(list_onet_titles_llm_risk_all))\n",
    "# index=142\n",
    "print(f\"Index: {index}\")\n",
    "print(f\"Title: {list_onet_titles_llm_risk_all[index]['title']}\")\n",
    "print(f\"Description: {list_onet_titles_llm_risk_all[index]['generation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLaMA2 doesn't quite work with output parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please respond with your setup, and I will provide the punchline for the joke"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2115.84 ms\n",
      "llama_print_timings:      sample time =    16.87 ms /    19 runs   (    0.89 ms per token,  1126.33 tokens per second)\n",
      "llama_print_timings: prompt eval time = 18890.75 ms /   219 tokens (   86.26 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:        eval time =  7297.68 ms /    18 runs   (  405.43 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time = 26322.54 ms\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse Joke from completion Please respond with your setup, and I will provide the punchline for the joke. Got: Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:25\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     24\u001b[0m     json_str \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup()\n\u001b[0;32m---> 25\u001b[0m json_object \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(json_str, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpydantic_object\u001b[39m.\u001b[39mparse_obj(json_object)\n",
      "File \u001b[0;32m~/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[39m'\u001b[39m\u001b[39mparse_constant\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mdecode(s)\n",
      "File \u001b[0;32m~/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m~/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m _input \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat_prompt(query\u001b[39m=\u001b[39mjoke_query)\n\u001b[1;32m     28\u001b[0m output \u001b[39m=\u001b[39m llm(_input\u001b[39m.\u001b[39mto_string())\n\u001b[0;32m---> 30\u001b[0m parser\u001b[39m.\u001b[39;49mparse(output)\n",
      "File \u001b[0;32m~/Documents/github/research-llms/venv/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:31\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     29\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpydantic_object\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m     30\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to parse \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m from completion \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m. Got: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[39mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[39m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse Joke from completion Please respond with your setup, and I will provide the punchline for the joke. Got: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=joke_query)\n",
    "\n",
    "output = llm(_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
